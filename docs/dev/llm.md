# LLM Package

- Providers: OpenAI, Anthropic (submodules)
- Status: Complete for chat/completion + streaming; structured output supported
- Next:
  - Add more providers (Azure OpenAI, Google, local runners)
  - Expand error mapping and usage accounting
  - Pluggable output validators

Publishing:
- Tag root and submodules together; document env config and quickstarts.
